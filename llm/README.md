# OTOBO LLM ü§ñ

> **Transforma o teu Service Desk num ecossistema inteligente.**
> Uma ponte segura entre o OTOBO Helpdesk e Modelos de Linguagem (LLMs), desenhada para automa√ß√£o de respostas, soberania de dados e suporte assistido.

Este projeto implementa uma camada de intelig√™ncia artificial sobre o OTOBO, permitindo duas funcionalidades cr√≠ticas sem alterar o c√≥digo base do helpdesk: **Respostas Autom√°ticas Contextuais** (via Email) e um **Assistente Virtual** (RAG) na dashboard do cliente.

---

## üöÄ Funcionalidades Principais

### 1. Automa√ß√£o de Tickets (Email Handler)
O sistema interceta notifica√ß√µes de novos tickets e gera respostas ou sugest√µes t√©cnicas imediatas.

* **Triagem Inteligente via Metadados:** O comportamento da IA √© definido pela configura√ß√£o da Fila (Queue) no OTOBO.
* **Contexto Din√¢mico:** Uma notifica√ß√£o vinda da fila "Recursos Humanos" gera uma resposta administrativa; uma vinda da fila "Servidores" gera uma resposta t√©cnica de SysAdmin.
* **Modo H√≠brido:**
    * **P√∫blico:** Envia uma sugest√£o de "auto-ajuda" diretamente ao cliente enquanto aguarda um agente.
    * **Interno (Shadow Mode):** Envia apenas uma nota oculta para os agentes com uma an√°lise preliminar e sugest√£o de resolu√ß√£o.

### 2. Assistente Virtual (Chat Widget)
Um chat integrado na interface do cliente (*Customer Dashboard*) que atua como primeira linha de suporte.

* **RAG (Retrieval-Augmented Generation):** O assistente consulta bases de conhecimento internas (Elasticsearch), manuais e estados de servi√ßo antes de responder.
* **Kill-Switch de Infraestrutura:** Se um servi√ßo cr√≠tico estiver em baixo (detetado via monitoriza√ß√£o), o chat informa imediatamente o utilizador sobre a avaria geral, impedindo sugest√µes de *troubleshooting* desnecess√°rias.
* **Privacidade:** Op√ß√£o de correr modelos locais (Ollama) ou transbordar para APIs externas apenas em picos de carga.

*Como exemplo para um template para o chat, poder√° ser utilizado o c√≥digo inclu√≠do no diret√≥rio templates na raiz deste projeto*
---

## ‚öôÔ∏è Integra√ß√£o: O Segredo est√° na Notifica√ß√£o

A integra√ß√£o n√£o requer plugins complexos. Utilizamos o sistema nativo de **Notifica√ß√µes de Eventos** do OTOBO para enviar o contexto necess√°rio √† IA.

### Como Configurar (Exemplo `Export-Notification.yml`)

Ao criar uma notifica√ß√£o no OTOBO (`AdminNotificationEvent`), injetamos um bloco de metadados no corpo do email que √© invis√≠vel para o utilizador final, mas interpretado pelo nosso servi√ßo.

**Exemplo de Corpo da Notifica√ß√£o:**

```yaml
Subject: 'LLM Request: [Ticket#<OTOBO_TICKET_TicketNumber>] <OTOBO_TICKET_Title>'
Body: |
  <p>
  ### METADATA START ###
  CustomerEmail: <OTOBO_CUSTOMER_DATA_UserEmail>
  TargetBCC: equipa.tecnica@tua-organizacao.com
  Internal: Yes  # AQUI DEFINES A PERSONALIDADE DA IA PARA ESTA FILA:
  SystemContext: O utilizador est√° a reportar problemas de Alojamento Web.
  Age como um SysAdmin S√©nior. S√™ conciso.
  Sugere verifica√ß√µes de DNS e acesso SSH.
  ### METADATA END ###

  <OTOBO_CUSTOMER_BODY[3000]>
  </p>
```
#Fluxo de Execu√ß√£o:

**Gatilho**: Ticket criado na Fila Alojamento Web.

**A√ß√£o**: OTOBO envia este email para o LLM-Email-Service (via SMTP local).

**Processamento**: O servi√ßo extrai o SystemContext, ignora o texto HTML extra, consulta o LLM e devolve a resposta ao ticket.

*Poder√° ser utilizado o exemplo de notifica√ß√£o inclu√≠do no Notification.yml

## üì¶ Arquitetura do Sistema

O sistema opera com microsservi√ßos que complementam o OTOBO:

### Componentes

* **`llm_email_service.py`**: Servidor SMTP Python que recebe as notifica√ß√µes, processa o pedido com base no `SystemContext` e envia a resposta. Inclui prote√ß√£o contra loops de email e m√©tricas de consumo energ√©tico.
* **`chat_proxy.py`**: API Middleware para o chat widget. Gere a mem√≥ria de conversa√ß√£o, faz a gest√£o de filas de espera e decide se a resposta deve vir da base de conhecimento local ou do LLM.
* **Search Modules**: Scripts personalizados que permitem ao LLM "ler" tickets antigos resolvidos (via Elasticsearch) ou consultar p√°ginas de estado de servi√ßos para dar respostas factuais.

## üõ°Ô∏è Privacidade e Seguran√ßa

Ideal para ambientes institucionais ou empresariais:

* **Sanitiza√ß√£o de Dados**: O sistema remove automaticamente padr√µes sens√≠veis (como URLs de redefini√ß√£o de password ou dados pessoais) antes de enviar o prompt para o modelo.
* **Soberania**: Preparado para funcionar 100% *on-premise* com modelos Open Source (Llama 3, Mistral, etc.), garantindo que dados confidenciais n√£o saem da infraestrutura.
* **Auditoria**: Todas as intera√ß√µes ficam registadas no pr√≥prio ticket do OTOBO como artigos (notas ou emails), permitindo revis√£o humana.

## üìã Requisitos

* **OTOBO** (ou outro sistema que fa√ßa uso do servi√ßo de mail com recurso a notifica√ß√µes).
* **Python**: 3.9+ (para os servi√ßos de middleware).
* **OpenWebUI**: Frontend essencial para servir a interface de chat e gerir a orquestra√ß√£o com o LLM.
* **SearXNG**: Motor de metapesquisa necess√°rio para executar as consultas RAG (Status, Tickets, Web).
* **Backend LLM**: Ollama (recomendado para local) ou endpoint compat√≠vel com OpenAI.
* **Acesso SMTP**: O servidor onde corre o servi√ßo de LLM deve conseguir enviar emails para o OTOBO.
